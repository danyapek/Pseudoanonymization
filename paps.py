# -*- coding: utf-8 -*-
"""PaPS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xLxwdPcj9La_73l0PesJ-K43yiYUHVGt

# **Розробка та оптимізація нейронної мережі для автоматичного визначення об'єктів на зображеннях та їх псевдонімізації**

Це перший модуль виконання магістерської роботи. Він включає в себе покрокові етапи навчання задля можливості подальшого втілення кінцевої ідеї. Тут розглядається лише практика зі статичними зображеннями та відео.

##**Перший модуль. Під'єднання**

### **Бібліотеки**
"""

import mediapipe as mp

import cv2

from google.colab.patches import cv2_imshow

"""### **Передбачення та маскування на зображенні**"""

img_path = '/content/test_2m.jpg'
img = cv2.imread(img_path)

H, W, _ = img.shape

mp_face_detecion = mp.solutions.face_detection

with mp_face_detecion.FaceDetection(min_detection_confidence = 0.5, model_selection = 0) as face_detection:
  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  out = face_detection.process(img_rgb)

  #print(out.detections) - для параметрів

  if out.detections is not None:
     ##перевірка обов'язкова, без неї при відстутності обличчя бувають помилки
     ##to-do: перевірити фото від 3х облич
    for detection in out.detections:
      location_data = detection.location_data
      bbox = location_data.relative_bounding_box

      x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height

      x1 = int(x1 * W)
      y1 = int(y1 * H)
      w = int(w * W)
      h = int(h * H)


      img_path = '/content/test_2m.jpg'
      img = cv2.imread(img_path)
      ## тест визначення
      img = cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (128, 0, 128), 5)
      cv2_imshow(img)
      cv2.waitKey(0)

"""Результат 2-5с, в залежності від ракурсу"""

img_path = '/content/test_2m.jpg'
img = cv2.imread(img_path)

def gaus_blur_face(img, y1, x1, w, h):
  img_blurred = cv2.GaussianBlur(img[y1:y1 + h, x1:x1 + w, :], (51, 51), 200)
  img[y1:y1 + h, x1:x1 + w, :] = img_blurred
  return img


img_blur = gaus_blur_face(img, y1, x1, w, h)


cv2_imshow(img_blur)
cv2.waitKey(0)

cv2.imwrite('/content/Output/test_cv2.jpg', img)

"""### **Передбачення та маскування відео**"""

from easydict import EasyDict
#Довелось замінити з argparse бо він не працює в Colab

def process_img(img, face_detection):
  H, W, _ = img.shape

  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  out = face_detection.process(img_rgb)

  H, W, _ = img.shape

  if out.detections is not None:
    for detection in out.detections:
      location_data = detection.location_data
      bbox = detection.location_data.relative_bounding_box

      x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height

      x1 = int(x1 * img.shape[1])
      y1 = int(y1 * img.shape[0])
      w = int(w * img.shape[1])
      h = int(h * img.shape[0])

      img_blurred = cv2.GaussianBlur(img[y1:y1 + h, x1:x1 + w, :], (51, 51), 200)
      img[y1:y1 + h, x1:x1 + w, :] = img_blurred

  return img

config = EasyDict({
  "mode": "video",  #"image" ||"video"
  "input_path": '/content/v_test.MP4',
  "output_path": '/content/Output/1stvideo.mp4',
})

mp_face_detection = mp.solutions.face_detection

with mp_face_detection.FaceDetection(model_selection = 0, min_detection_confidence = 0.3) as face_detection:

  if config.mode == "image":
    img = cv2.imread(config.input_path)
    img = process_img(img, face_detection)
    cv2.imwrite(config.output_path + ".jpg", img)

  elif config.mode == "video":
    cap = cv2.VideoCapture(config.input_path)
    ret, frame = cap.read()
    #Замість того щоб хардкодити фпс
    fps = cap.get(cv2.CAP_PROP_FPS)
    output_vid = cv2.VideoWriter(config.output_path,
                                 cv2.VideoWriter_fourcc(*"mp4v"),
                                 fps,
                                  (frame.shape[1],
                                   frame.shape[0])
                                )

    while ret:
      modified_frame = process_img(frame.copy(), face_detection)
      frame = modified_frame
      output_vid.write(frame)
      ret, frame = cap.read()

    cap.release()
    output_vid.release()